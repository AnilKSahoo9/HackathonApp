{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a12ca2bd",
   "metadata": {},
   "source": [
    "### OCI Data Science - Useful Tips\n",
    "<details>\n",
    "<summary><font size=\"2\">Check for Public Internet Access</font></summary>\n",
    "\n",
    "```python\n",
    "import requests\n",
    "response = requests.get(\"https://oracle.com\")\n",
    "assert response.status_code==200, \"Internet connection failed\"\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Helpful Documentation </font></summary>\n",
    "<ul><li><a href=\"https://docs.cloud.oracle.com/en-us/iaas/data-science/using/data-science.htm\">Data Science Service Documentation</a></li>\n",
    "<li><a href=\"https://docs.cloud.oracle.com/iaas/tools/ads-sdk/latest/index.html\">ADS documentation</a></li>\n",
    "</ul>\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Typical Cell Imports and Settings for ADS</font></summary>\n",
    "\n",
    "```python\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(levelname)s:%(message)s', level=logging.ERROR)\n",
    "\n",
    "import ads\n",
    "from ads.dataset.factory import DatasetFactory\n",
    "from ads.automl.provider import OracleAutoMLProvider\n",
    "from ads.automl.driver import AutoML\n",
    "from ads.evaluations.evaluator import ADSEvaluator\n",
    "from ads.common.data import ADSData\n",
    "from ads.explanations.explainer import ADSExplainer\n",
    "from ads.explanations.mlx_global_explainer import MLXGlobalExplainer\n",
    "from ads.explanations.mlx_local_explainer import MLXLocalExplainer\n",
    "from ads.catalog.model import ModelCatalog\n",
    "from ads.common.model_artifact import ModelArtifact\n",
    "```\n",
    "</details>\n",
    "<details>\n",
    "<summary><font size=\"2\">Useful Environment Variables</font></summary>\n",
    "\n",
    "```python\n",
    "import os\n",
    "print(os.environ[\"NB_SESSION_COMPARTMENT_OCID\"])\n",
    "print(os.environ[\"PROJECT_OCID\"])\n",
    "print(os.environ[\"USER_OCID\"])\n",
    "print(os.environ[\"TENANCY_OCID\"])\n",
    "print(os.environ[\"NB_REGION\"])\n",
    "```\n",
    "</details>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b2f9575b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "usage: odsc [-h] {conda,core-site} ...\n",
      "odsc: error: unrecognized arguments: -y\n"
     ]
    }
   ],
   "source": [
    "!odsc  conda  install -s mlcpuv1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "819c8f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sklearn\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import MinMaxScaler,LabelEncoder\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multioutput import MultiOutputClassifier\n",
    "import random\n",
    "\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "49c36d95",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=pd.read_csv('fake_dataset (1).csv', engine='python')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "036ff00e",
   "metadata": {},
   "outputs": [],
   "source": [
    "duplicates=['','ike','onate books ','alk to elderly','o to framer market','olunteer to a Cause','upport local produce',\n",
    "            'uy  handmade products','upport startups ideas','ake an emergency package','ttend  community service',\n",
    "            'elp someone with your skills','ontribute to local communities','ntroduce your self to your neighbours',\n",
    "            'uy from \"nothing group\" facebook group','repare your emergency kit for fire diaster',\n",
    "            'eliver grocery or medications to neighbours','nvitee community member to your celebrations',\n",
    "            'ake a test to check your wellbeing after disaster','onate local hospitals and well being centres online',\n",
    "            'heck if the house is at risk by looking at the flood map',\n",
    "            'egister at flood warning service/ and bureau of meteorology warning service']\n",
    "for i in range(data.shape[0]):\n",
    "    temp_list=data['acts'].values[i].split(',')\n",
    "    for item in temp_list:\n",
    "        if item in duplicates:\n",
    "            data['acts'].values[i]=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aa3f664c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(17520, 12)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=data.dropna()\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8e946e47",
   "metadata": {},
   "outputs": [],
   "source": [
    "acts_list=[]\n",
    "for i in range(data.shape[0]):\n",
    "    temp_list=data['acts'].values[i].split(',')\n",
    "    for item in temp_list:\n",
    "        if not (item in acts_list):\n",
    "            acts_list.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3a056ae0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for item in acts_list:\n",
    "    data[item]=None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c8bbf420",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ndata[\\'acts_num\\']=\\'0\\'\\nfor i in range(data.shape[0]):\\n    temp_list=data[\\'acts\\'].values[i].split(\\',\\')\\n    temp_arr=[\\'0\\']*39\\n    for item_i in range(len(acts_list)):\\n        if acts_list[item_i] in temp_list:\\n            temp_arr[item_i]=\\'1\\'\\n    \\n    data[\\'acts_num\\'].values[i]=\"\".join(str(x) for x in temp_arr)\\n'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "for i in range(data.shape[0]):\n",
    "    temp_list=data['acts'].values[i].split(',')\n",
    "    for item in acts_list:\n",
    "        if item in temp_list:\n",
    "            \n",
    "            data[item].values[i]=1\n",
    "        else:\n",
    "            data[item].values[i]=0\n",
    "'''\n",
    "data['acts_num']='0'\n",
    "for i in range(data.shape[0]):\n",
    "    temp_list=data['acts'].values[i].split(',')\n",
    "    temp_arr=['0']*39\n",
    "    for item_i in range(len(acts_list)):\n",
    "        if acts_list[item_i] in temp_list:\n",
    "            temp_arr[item_i]='1'\n",
    "    \n",
    "    data['acts_num'].values[i]=\"\".join(str(x) for x in temp_arr)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "89178acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "data=data.drop(['acts','name'],axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d3d565f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "outdoor_0_acts=['Prepare your emergency kit for flood diaster','Prepare your emergency kit for fire diaster',\n",
    "               'Create educational material to show impact of disaster impact',\n",
    "                'Register at flood warning service/ and bureau of meteorology warning service',\n",
    "                'Check if the house is at risk by looking at the flood map',\n",
    "                'Make an emergency package','Support startups ideas','Donate local hospitals and well being centres online',\n",
    "                'Donate plants/tree to school or communitysupport local meetup group'\n",
    "               ]\n",
    "data['outdoor']=1\n",
    "for i in range(data.shape[0]):\n",
    "    for outdoor_act in outdoor_0_acts:\n",
    "        if data[outdoor_act].values[i]:\n",
    "            data['outdoor'].values[i]=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b1fd63bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "disaster_history=pd.read_csv('disaster_history_coord.csv')\n",
    "disaster_history.head(2)\n",
    "fire_lat_lon=disaster_history[['lat','lon']][disaster_history['cateogory']=='Bushfire']\n",
    "flood_lat_lon=disaster_history[['lat','lon']][disaster_history['cateogory']=='Flood']\n",
    "fire_acts=['Prepare your emergency kit for fire diaster','Create educational material to show impact of disaster impact',\n",
    "          'Make an emergency package']\n",
    "flood_acts=['Create educational material to show impact of disaster impact',\n",
    "           'Prepare your emergency kit for fire diaster','Register at flood warning service/ and bureau of meteorology warning service',\n",
    "           'Check if the house is at risk by looking at the flood map','Make an emergency package']\n",
    "\n",
    "for i in range(data.shape[0]):\n",
    "    for fire_act in fire_acts:\n",
    "        if data[fire_act].values[i]:\n",
    "            rand_fire_act_ind=np.random.randint(fire_lat_lon.shape[0])\n",
    "            dec_lat = random.random()/100\n",
    "            dec_lng = random.random()/100\n",
    "            data['lat'].values[i]=fire_lat_lon.values[rand_fire_act_ind,0]+dec_lat\n",
    "            data['lng'].values[i]=fire_lat_lon.values[rand_fire_act_ind,1]+dec_lng\n",
    "            \n",
    "    for flood_act in flood_acts:\n",
    "        if data[flood_act].values[i]:\n",
    "            rand_flood_act_ind=np.random.randint(flood_lat_lon.shape[0])\n",
    "            dec_lat = random.random()/100\n",
    "            dec_lng = random.random()/100\n",
    "            data['lat'].values[i]=flood_lat_lon.values[rand_flood_act_ind,0]+dec_lat\n",
    "            data['lng'].values[i]=flood_lat_lon.values[rand_flood_act_ind,1]+dec_lng\n",
    "\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "550a8095",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_cols=data.columns\n",
    "input_cols=all_cols[:10]\n",
    "out_cols=all_cols[10:]\n",
    "t = [('num', MinMaxScaler(), input_cols)]\n",
    "col_transform = ColumnTransformer(transformers=t,remainder='passthrough')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9b1b54d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Pipeline(steps=[('transformer', col_transform),\n",
    "                      #('classifier',RandomForestClassifier(n_estimators=100))\n",
    "                       ('classifier',RandomForestClassifier())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "cf10f301",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hard accuracies\n",
      "Training accuracy 92.24740160163572\n",
      "Test accuracy 0.0\n",
      "Soft accuracies\n",
      "Training accuracy 99.14369721832662\n",
      "Test accuracy 80.83264596581787\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "for i in range(len(out_cols)):\n",
    "    X=data.iloc[:,:10]#.astype(np.float32)\n",
    "    y=data.iloc[:,10+i].astype(np.uint8)\n",
    "    Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.2)\n",
    "    model.fit(Xtrain,ytrain)\n",
    "    print('Training accuracy',model.score(Xtrain,ytrain))\n",
    "    print('Test accuracy',model.score(Xtest,ytest))\n",
    "'''\n",
    "### MULTIMODEL TRAINING\n",
    "model_list=[]\n",
    "for col in out_cols:\n",
    "    temp_model = Pipeline(steps=[('transformer', col_transform),\n",
    "                  ('classifier',RandomForestClassifier(n_estimators=100))\n",
    "                   #('classifier',KNeighborsClassifier())\n",
    "                                ])\n",
    "\n",
    "    X=data.iloc[:,:10]#.astype(np.float32)\n",
    "    y=data[col].astype(np.uint8)\n",
    "    Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.33,random_state=2021)\n",
    "    temp_model.fit(Xtrain,ytrain)\n",
    "    model_list.append(temp_model)\n",
    "\n",
    "\n",
    "X=data.iloc[:,:10]#.astype(np.float32)\n",
    "y=data.iloc[:,10:].astype(np.uint8)\n",
    "Xtrain,Xtest,ytrain,ytest=train_test_split(X,y,test_size=0.33,random_state=2021)  \n",
    "pred_ytest=np.zeros(ytest.shape)\n",
    "pred_ytrain=np.zeros(ytrain.shape)\n",
    "for i in range(y.shape[1]):\n",
    "    pred_ytest[:,i]=model_list[i].predict(Xtest)\n",
    "    pred_ytrain[:,i]=model_list[i].predict(Xtrain)\n",
    "\n",
    "print('Hard accuracies')\n",
    "total=0\n",
    "correct=0\n",
    "for i in range(ytrain.shape[0]):\n",
    "    if (ytrain.values[i,:]==pred_ytrain[i,:]).all():\n",
    "        correct+=1\n",
    "    total+=1\n",
    "print('Training accuracy',100*correct/total)\n",
    "\n",
    "\n",
    "total=0\n",
    "correct=0\n",
    "for i in range(ytest.shape[0]):\n",
    "    if (ytest.values[i,:]==pred_ytest[i,:]).all():\n",
    "        correct+=1\n",
    "    total+=1\n",
    "print('Test accuracy',100*correct/total)\n",
    "\n",
    "\n",
    "print('Soft accuracies')\n",
    "total=0\n",
    "correct=0\n",
    "for i in range(ytrain.shape[0]):\n",
    "    for j in range(ytrain.shape[1]):\n",
    "        if (ytrain.values[i,j]==pred_ytrain[i,j]):\n",
    "            correct+=1\n",
    "        total+=1\n",
    "print('Training accuracy',100*correct/total)\n",
    "\n",
    "\n",
    "total=0\n",
    "correct=0\n",
    "for i in range(ytest.shape[0]):\n",
    "    for j in range(ytest.shape[1]):\n",
    "        if (ytest.values[i,j]==pred_ytest[i,j]):\n",
    "            correct+=1\n",
    "        total+=1\n",
    "print('Test accuracy',100*correct/total)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6db5198c",
   "metadata": {},
   "outputs": [],
   "source": [
    "        \n",
    "def MultiModelpredict(name,age,lat,lng,disable,outdoor,preparation,community,local_support,environment,asset_protection):\n",
    "    \n",
    "    input_vals=np.array([age,lat,lng,disable,outdoor,preparation,community,local_support,environment,asset_protection])\n",
    "\n",
    "    df_input=pd.DataFrame(input_vals.reshape(1,-1))\n",
    "    df_input.columns=input_cols\n",
    "    transformed_output=np.zeros(len(out_cols))\n",
    "    transformed_output_probs=np.zeros(len(out_cols))\n",
    "    for i in range(len(out_cols)):\n",
    "        transformed_output[i]=np.squeeze(model_list[i].predict(df_input))\n",
    "        transformed_output_probs[i]=max(np.squeeze(model_list[i].predict_proba(df_input)))\n",
    "\n",
    "    pred_acts=[]\n",
    "    confidence=[]\n",
    "    for i in range(transformed_output.shape[0]):\n",
    "        if transformed_output[i]:\n",
    "            pred_acts.append(out_cols[i])\n",
    "            confidence.append(transformed_output_probs[i])\n",
    "    return pred_acts,confidence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6bccf271",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(['Donate books ',\n",
       "  'movies and newspaper to library',\n",
       "  'Help in your neighbors garden',\n",
       "  'Buy  handmade products',\n",
       "  'Buy from \"nothing group\" facebook group',\n",
       "  'Place a bird feeder',\n",
       "  'Take a test to check your wellbeing after disaster'],\n",
       " [0.58, 0.61, 0.65, 0.64, 0.92, 0.59, 0.6])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "MultiModelpredict('John Cena',50,-32.0525,115.8878,False,True,0,1,1,1,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "0dbd088d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#transformed_data=col_transform.fit_transform(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "7118d7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "#model=RandomForestClassifier()\n",
    "#model.fit(Xtrain, ytrain)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4df8e52e",
   "metadata": {},
   "outputs": [],
   "source": [
    "breakpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5b8c0869",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: requests in ./conda/mlcpuv1/lib/python3.6/site-packages (2.25.0)\n",
      "Collecting flask\n",
      "  Downloading Flask-1.1.2-py2.py3-none-any.whl (94 kB)\n",
      "\u001b[K     |████████████████████████████████| 94 kB 3.4 MB/s  eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: Werkzeug>=0.15 in ./conda/mlcpuv1/lib/python3.6/site-packages (from flask) (1.0.1)\n",
      "Requirement already satisfied: Jinja2>=2.10.1 in ./conda/mlcpuv1/lib/python3.6/site-packages (from flask) (2.11.2)\n",
      "Requirement already satisfied: click>=5.1 in ./conda/mlcpuv1/lib/python3.6/site-packages (from flask) (6.7)\n",
      "Requirement already satisfied: idna<3,>=2.5 in ./conda/mlcpuv1/lib/python3.6/site-packages (from requests) (2.10)\n",
      "Requirement already satisfied: urllib3<1.27,>=1.21.1 in ./conda/mlcpuv1/lib/python3.6/site-packages (from requests) (1.25.11)\n",
      "Requirement already satisfied: chardet<4,>=3.0.2 in ./conda/mlcpuv1/lib/python3.6/site-packages (from requests) (3.0.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in ./conda/mlcpuv1/lib/python3.6/site-packages (from requests) (2020.12.5)\n",
      "Collecting itsdangerous>=0.24\n",
      "  Downloading itsdangerous-1.1.0-py2.py3-none-any.whl (16 kB)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in ./conda/mlcpuv1/lib/python3.6/site-packages (from Jinja2>=2.10.1->flask) (1.1.1)\n",
      "Installing collected packages: itsdangerous, flask\n",
      "Successfully installed flask-1.1.2 itsdangerous-1.1.0\n"
     ]
    }
   ],
   "source": [
    "#!pip install flask  requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "55057dab",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2021-04-18 21:13:22--  https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-386.zip\n",
      "Resolving bin.equinox.io (bin.equinox.io)... 54.226.184.31, 3.212.138.198, 54.175.245.12, ...\n",
      "Connecting to bin.equinox.io (bin.equinox.io)|54.226.184.31|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 14311173 (14M) [application/octet-stream]\n",
      "Saving to: ‘ngrok-stable-linux-386.zip’\n",
      "\n",
      "100%[======================================>] 14,311,173  5.24MB/s   in 2.6s   \n",
      "\n",
      "2021-04-18 21:13:26 (5.24 MB/s) - ‘ngrok-stable-linux-386.zip’ saved [14311173/14311173]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#!wget https://bin.equinox.io/c/4VmDzA7iaHb/ngrok-stable-linux-386.zip"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:mlcpuv1]",
   "language": "python",
   "name": "conda-env-mlcpuv1-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
